{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "\n",
    "* Review gradient descent without vectors\n",
    "* Gradient descent as ML \n",
    "* Gradient descent with vectors\n",
    "* Closed form with vectors \n",
    "* Closed form with matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Machine learning is fast growing, but our initial technique of regression was developed by Gauss in 1800\n",
    "\n",
    "* The topic of Machine Learning has taken off because of \n",
    "    1. Gains in computer power \n",
    "    2. A lot of available data \n",
    "    3. Algorithmic advances in the last 30 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What's going on is out of our hands \n",
    "* Not explicitly telling the program what to do \n",
    "* Using rules to modify our function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is machine learning \n",
    "\n",
    "* It's a data driven way to write a program \n",
    "* For example, consider our regression problem of predicting the revenue of movies.  We could just tell our program to multiply movie budget by some number to get the movie budget.  The ML part is that our algorithm learns these numbers associated with our model.  So it helps to build the model.\n",
    "\n",
    "* So in normal programming, we know the rules and ask computers to apply them, whereas in ML the computers find the rules and can do the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are things that are hard to program manually but things that are easy to collect lots of data for, and that's where ml is successful "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|** Training data**   | ** ML Algorithm **   | **Predictions** |\n",
    "|---                  |---                   |---|\n",
    "| $(x^1, y^1)$   | Hypothesis Function    | $(x_i, \\hat y) $|\n",
    "|  $(x^2, y^2)$  |     $y^i = h(x^i)$        |      |\n",
    "|  $(x^2, y^2)$  |   Train min $E(\\theta) $       |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised learning \n",
    "\n",
    "* Where we provide both the algorithm inputs and target labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{iceCream} = \\theta_1 * temperature + \\theta_2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "canonical supervised machine learning problem:\n",
    "    \n",
    "$ min E(\\theta) = \\sum_{i=1}^n l(h_\\theta(x_i), y_i) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. loss function:  $\\sum (y_i - h(x_i))^2$\n",
    "\n",
    "2. hypothesis function \n",
    "$h(x_i) = \\sum_{j = 1}^n x_j*\\theta_j  = x_i^T \\cdot \\theta$\n",
    "\n",
    "\n",
    "3. inputs - [85, 1, 1], $ x^{(i)} \\in R^n$\n",
    "4. outputs - $ y^i \\in R $\n",
    "5. thetas - $\\theta \\in R^n $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example\n",
    "\n",
    "* Modeling a problem.  For example our ice cream demand \n",
    "\n",
    "$\\hat{iceCream} = \\theta_1 * temperature + \\theta_2$ \n",
    "\n",
    "How good does this model do?\n",
    "\n",
    "* $E = (y^i - \\hat y)^2$\n",
    "\n",
    "* $ E = (y^i - \\hat y)^2$\n",
    "\n",
    "$ E(\\theta) = \\frac{1}{num days} \\sum_{i \\in days} (demand - \\theta_1*temp + \\theta_2 )^2 $ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So formally for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. hypothesis:  $h_\\theta^i(x) = \\sum_j^n \\theta_{j = 1} \\times x_j$\n",
    "\n",
    "2. loss function: $l(\\hat y, y) = (\\hat y  - y)^2 $\n",
    "\n",
    "3. $ min \\theta \\sum^m_{i = 1} ( \\sum_{j=1}^n \\theta_{j}* x_j)  - y^{(i)})^2$\n",
    "\n",
    "### First mechanism: gradient descent \n",
    "A. gradient descent \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First mechanism: gradient descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Illustration of a function and it's derivative.](./resources/opt_grad.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ (y_i - (\\theta_1*x_1 + \\theta_2x_2 + \\theta_3))^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta E}{\\delta \\theta_1} = -2\\sum_{i=1}^m *x_1(y_i - (\\theta_1*x_1 + \\theta_2x_2 + \\theta_3)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta E}{\\delta \\theta_2} = -2\\sum_{i=1}^m *x_2(y_i - (\\theta_1*x_1 + \\theta_2x_2 + \\theta_3)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac {\\delta E}{\\delta \\theta_k} =  -2\\sum_{i=1}^m *x_k(y_i - (\\theta_1*x_1 + \\theta_2x_2 + \\theta_3)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac {\\delta E}{\\delta \\theta_k} =  -2\\sum_{i=1}^m *x_k(error) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* University of Washington Coursera - regression * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\theta_1 = \\theta_1 + \\alpha*\\frac{\\delta E}{\\delta \\theta_1} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We want to find how to update our function, and we do that with the derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ml-cheatsheet.readthedocs.io/en/latest/calculus.html\n",
    "\n",
    "http://www.stat.purdue.edu/~boli/stat512/lectures/topic3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mysite.science.uottawa.ca/rkulik/mat3378/mat3378-textbook.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@andrew.chamberlain/the-linear-algebra-view-of-least-squares-regression-f67044b7f39b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
